{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer # Imputing missing values\nfrom imblearn.under_sampling import RandomUnderSampler # Class Imbalance\n\n# Numerical features selection\nfrom sklearn.decomposition import PCA \n\n# Categorical Features Selection\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\n# Classification Models\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import naive_bayes\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\n# Model Optimization\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Metrics\nfrom sklearn import metrics\n\n# Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.compose import ColumnTransformer\n\n# Other General Imports\nimport gc\n%matplotlib inline\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-11-25T16:56:36.505763Z","iopub.execute_input":"2022-11-25T16:56:36.506262Z","iopub.status.idle":"2022-11-25T16:56:37.099093Z","shell.execute_reply.started":"2022-11-25T16:56:36.506165Z","shell.execute_reply":"2022-11-25T16:56:37.096976Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading and Reducing the Size\n\nSince the data is big in size, we will use function to reduce its memory for fast processing and consuming less storage.","metadata":{}},{"cell_type":"code","source":"start = time.time()\n# Helper function\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-11-25T16:56:40.010468Z","iopub.execute_input":"2022-11-25T16:56:40.010871Z","iopub.status.idle":"2022-11-25T16:56:40.025671Z","shell.execute_reply.started":"2022-11-25T16:56:40.010839Z","shell.execute_reply":"2022-11-25T16:56:40.023868Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# loading train_transaction data\ntt = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')\nprint(tt.shape)\ntt = reduce_mem_usage(tt)\n\n# loading train_transaction data\nti = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\nprint(ti.shape)\nti = reduce_mem_usage(ti)\n\ntrain = pd.merge(tt, ti, how = 'left')\nprint('Train shape',train.shape)\n\ntrain.head()\n\ndel tt, ti","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading test_transaction data\nts = pd.read_csv('../input/ieee-fraud-detection/test_transaction.csv')\nprint(ts.shape)\nts = reduce_mem_usage(ts)\n\ntsi = pd.read_csv('../input/ieee-fraud-detection/test_identity.csv')\nprint(tsi.shape)\ntsi = reduce_mem_usage(tsi)\n\ntest = pd.merge(ts, tsi, how = 'left')\nprint('Test shape',test.shape)\ntest.head()\n\ndel ts, tsi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"def summary(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n\n    return summary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(test)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering 1","metadata":{}},{"cell_type":"markdown","source":"### Handling and Genearating Features","metadata":{}},{"cell_type":"code","source":"def Devices(df):\n    df['device_name'] = df['DeviceInfo'].str.split('/', expand=True)[0]\n    df['device_version'] = df['DeviceInfo'].str.split('/', expand=True)[1]\n    df = df.drop(['DeviceInfo'], axis = 1)\n    \n    df['OS_id_30'] = df['id_30'].str.split(' ', expand=True)[0]\n    df['version_id_30'] = df['id_30'].str.split(' ', expand=True)[1]\n    df = df.drop(['id_30'], axis = 1)\n    \n    df['browser_id_31'] = df['id_31'].str.split(' ', expand=True)[0]\n    df['version_id_31'] = df['id_31'].str.split(' ', expand=True)[1]\n    df = df.drop(['id_31'], axis = 1)\n\n    df['screen_width'] = df['id_33'].str.split('x', expand=True)[0]\n    df['screen_height'] = df['id_33'].str.split('x', expand=True)[1]\n    df = df.drop(['id_33'], axis = 1)\n\n    df['id_34'] = df['id_34'].str.split(':', expand=True)[1]\n    df['id_23'] = df['id_23'].str.split(':', expand=True)[1]\n    df = df.drop(['id_34', 'id_23'], axis = 1)\n\n\n    df.loc[df['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n    df.loc[df['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n    df.loc[df['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n    df.loc[df['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n    df.loc[df['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n    df.loc[df['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n    df.loc[df['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n    df.loc[df['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n    df.loc[df['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n    df.loc[df['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n    df.loc[df['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n    df.loc[df['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n    df.loc[df['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n    df.loc[df['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n    df.loc[df['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n    df.loc[df['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n    df.loc[df['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n\n    df.loc[df.device_name.isin(df.device_name.value_counts()[df.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n    df['had_id'] = 1\n    gc.collect()\n    \n    return df\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-25T16:56:43.504214Z","iopub.execute_input":"2022-11-25T16:56:43.505320Z","iopub.status.idle":"2022-11-25T16:56:43.524000Z","shell.execute_reply.started":"2022-11-25T16:56:43.505275Z","shell.execute_reply":"2022-11-25T16:56:43.522350Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = Devices(train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def DevicesT(df):\n    df['device_name'] = df['DeviceInfo'].str.split('/', expand=True)[0]\n    df['device_version'] = df['DeviceInfo'].str.split('/', expand=True)[1]\n    df = df.drop(['DeviceInfo'], axis = 1)\n    \n    df['OS_id_30'] = df['id-30'].str.split(' ', expand=True)[0]\n    df['version_id_30'] = df['id-30'].str.split(' ', expand=True)[1]\n    df = df.drop(['id-30'], axis = 1)\n    \n    df['browser_id_31'] = df['id-31'].str.split(' ', expand=True)[0]\n    df['version_id_31'] = df['id-31'].str.split(' ', expand=True)[1]\n    df = df.drop(['id-31'], axis = 1)\n\n    df['screen_width'] = df['id-33'].str.split('x', expand=True)[0]\n    df['screen_height'] = df['id-33'].str.split('x', expand=True)[1]\n    df = df.drop(['id-33'], axis = 1)\n\n    df['id-34'] = df['id-34'].str.split(':', expand=True)[1]\n    df['id-23'] = df['id-23'].str.split(':', expand=True)[1]\n    df = df.drop(['id-34', 'id-23'], axis = 1)\n\n\n    df.loc[df['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n    df.loc[df['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n    df.loc[df['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n    df.loc[df['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n    df.loc[df['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n    df.loc[df['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n    df.loc[df['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n    df.loc[df['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n    df.loc[df['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n    df.loc[df['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n    df.loc[df['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n    df.loc[df['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n    df.loc[df['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n    df.loc[df['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n    df.loc[df['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n    df.loc[df['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n    df.loc[df['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n\n    df.loc[df.device_name.isin(df.device_name.value_counts()[df.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n    df['had_id'] = 1\n    gc.collect()\n    \n    return df\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-25T16:56:51.248236Z","iopub.execute_input":"2022-11-25T16:56:51.248940Z","iopub.status.idle":"2022-11-25T16:56:51.267207Z","shell.execute_reply.started":"2022-11-25T16:56:51.248891Z","shell.execute_reply":"2022-11-25T16:56:51.266010Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test = DevicesT(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dealing with Missing Data","metadata":{}},{"cell_type":"code","source":"y = train['isFraud']\nTrainTransactionID = train['TransactionID']\nTrainTransactionDT = train['TransactionDT']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TestTransactionID = test['TransactionID']\nTestTransactionDT = test['TransactionDT']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(['TransactionID', 'TransactionDT' , 'isFraud'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.drop(['TransactionID', 'TransactionDT'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping columns with more than 80% missing values \nprint(\"Train shape before dropping features more than 30% missing values: \", train.shape)\nmv = train.isnull().sum()/len(train)\ntrain = train.drop(columns=mv[mv>0.7].index)\n\nprint(\"Train shape after dropping features more than 30% missing values: \", train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test shape before dropping features more than 30% missing values: \", test.shape)\nmv = test.isnull().sum()/len(test)\ntest = test.drop(columns=mv[mv>0.7].index)\n\nprint(\"Test shape after dropping features more than 30% missing values: \", test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dropna(how= 'all', axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.dropna(how= 'all', axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtering numerical data\nnum_df = train.select_dtypes(include=np.number)\nprint(num_df.shape)\n\n# Filtering categorical data\ncat_df = train.select_dtypes(exclude=np.number)\nprint(cat_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtering numerical data\nnum_df_test = test.select_dtypes(include=np.number)\nprint(num_df.shape)\n\n# Filtering categorical data\ncat_df_test = test.select_dtypes(exclude=np.number)\nprint(cat_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ndel test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing values by median for numerical columns \nimp_median = SimpleImputer(missing_values=np.nan, strategy='median')\nnum_df = pd.DataFrame(imp_median.fit_transform(num_df), columns=num_df.columns)\nprint(num_df.shape)\n\n# Filling missing values by most frequent value for categorical columns\nfor i in cat_df:\n    cat_df[i] = cat_df[i].fillna(np.NaN)\n    \ncat_df.isnull().sum()\nnum_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing values by median for numerical columns \nimp_median = SimpleImputer(missing_values=np.nan, strategy='median')\nnum_df_test = pd.DataFrame(imp_median.fit_transform(num_df_test), columns=num_df_test.columns)\nprint(num_df_test.shape)\n\n# Filling missing values by most frequent value for categorical columns\nfor i in cat_df_test:\n    cat_df_test[i] = cat_df_test[i].fillna(np.NaN)\n    \ncat_df_test.isnull().sum()\nnum_df_test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numerical Features","metadata":{}},{"cell_type":"code","source":"scaled_num = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(num_df), columns = num_df.columns)\nscaled_num.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_num_test = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(num_df_test), columns = num_df_test.columns)\nscaled_num_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PCA for Numerical Features","metadata":{}},{"cell_type":"code","source":"#optimuadd_suffixm number of components\npca = PCA().fit(scaled_num)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel(\"number of components\")\nplt.ylabel(\"Cumulative Rate of Variance\")\n\n#final\npca = PCA(n_components = 0.99)\n\npca_fit = pca.fit_transform(scaled_num)\nnum_pca = pd.DataFrame(data = pca_fit)\npca.explained_variance_ratio_.sum()\ndel num_df, scaled_num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_pca.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#optimuadd_suffixm number of components\npca_test = PCA().fit(scaled_num_test)\nplt.plot(np.cumsum(pca_test.explained_variance_ratio_))\nplt.xlabel(\"number of components\")\nplt.ylabel(\"Cumulative Rate of Variance\")\n\n#final\npca_test = PCA(n_components = 68)\n\npca_fit_test = pca_test.fit_transform(scaled_num_test)\nnum_pca_test = pd.DataFrame(data = pca_fit_test)\npca_test.explained_variance_ratio_.sum()\ndel num_df_test, scaled_num_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_pca_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Features","metadata":{}},{"cell_type":"markdown","source":"Due to we have too many values in some categories, we try to map them into new categories.","metadata":{}},{"cell_type":"code","source":"for x in cat_df.columns:\n    #printing unique values\n    print(x ,':', len(cat_df[x].unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_df = pd.get_dummies(cat_df)\ncat_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_df_test = pd.get_dummies(cat_df_test)\ncat_df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tree-based Categorical Feature Selection","metadata":{}},{"cell_type":"code","source":"clf = ExtraTreesClassifier(n_estimators=200, criterion = 'entropy')\nclf = clf.fit(cat_df, y)\n\nmodel = SelectFromModel(clf, prefit=True)\nfeature_idx = model.get_support()\nfeature_name = cat_df.columns[feature_idx]\n\ncat_new = pd.DataFrame(model.transform(cat_df), columns = feature_name)\ncat_new.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_new_test = pd.DataFrame(cat_df_test, columns = feature_name)\ncat_new_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Concatenating Numerical and Categorical Features ","metadata":{}},{"cell_type":"code","source":"# Concatinating numerical and categorical data\ntrain = pd.concat([y, num_pca, cat_df], axis=1)\ntrain = pd.DataFrame(train)\n\n# Verifying missing values\nprint(f'Total missing values: {train.isnull().sum().sum()}')\nprint(train.shape)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del  num_pca, cat_df, cat_new, y\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatinating numerical and categorical data\ntest = pd.concat([num_pca_test, cat_df_test], axis=1)\ntest = pd.DataFrame(test)\n\n# Verifying missing values\nprint(f'Total missing values: {test.isnull().sum().sum()}')\nprint(test.shape)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del  cat_df_test, num_pca_test, cat_new_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = reduce_mem_usage(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['isFraud']\nX = train.drop(['isFraud'], axis = 1)\nX_array=np.array(X)\n\nrus = RandomUnderSampler(random_state=0)\nX_resampled, y_resampled = rus.fit_resample(X, y)\n\nprint(X_resampled.shape, y_resampled.shape)\n\npd.value_counts(y_resampled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_df = pd.DataFrame(X_resampled, columns = X.columns)\ny_df = pd.DataFrame(y_resampled)\ndf = pd.concat([X_df, y_df], axis= 1)\ndf.shape \ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop([\"isFraud\"], axis = 1)\ny = df[\"isFraud\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler \nfrom hyperopt import tpe, hp, fmin, STATUS_OK,Trials\nfrom hyperopt.pyll.base import scope","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n\nspace = {\n    \"bootstrap\": hp.choice(\"bootstrap\", [False]),\n    \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 1400, 1600, 1800, 2000]),\n    \"max_depth\": hp.choice(\"max_depth\", [10, 20, 30, 40, 50, 100, 200, 250, 300, 350, 400]),\n    \"criterion\": hp.choice(\"criterion\", [\"entropy\"]),\n    \"max_features\": hp.choice(\"max_features\", ['sqrt', 'auto']),\n    \"min_samples_leaf\": hp.choice (\"min_samples_leaf\", [1, 3, 5, 7, 9]),\n    \"min_samples_split\": hp.choice(\"min_samples_split\", [2, 5, 8, 10, 12, 15, 20])\n    \n}\n\ndef hyperparameter_tuning(params):\n    rf = RandomForestClassifier(**params,n_jobs=-1, verbose = 0)\n    rf.fit(X_train, y_train)\n    y_scores = rf.predict_proba(X_test)\n    roc= metrics.roc_auc_score(y_test, y_scores[:,1])\n    return {\"loss\": -roc, \"status\": STATUS_OK}\n\n\ntrials = Trials()\n\nbest = fmin(\n    fn=hyperparameter_tuning,\n    space = space, \n    algo=tpe.suggest, \n    max_evals=5, \n    trials=trials\n)\n\nprint(\"Best: {}\".format(best))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(bootstrap = False,\n                            criterion = \"entropy\",\n                            max_depth= 350,\n                            n_estimators= 1600,\n                            min_samples_split = 12,\n                            min_samples_leaf = 3,\n                            max_features= 'sqrt')\n\n\nrf.fit(X_train, y_train)\ny_scores = rf.predict_proba(X_test)\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_scores[:,1])\nRFScore = metrics.auc(fpr, tpr)\nprint(RFScore)\n\n\n# plot ROC curve\nfig = plt.figure(figsize=(6, 6))\n# Plot the diagonal 50% line\nplt.plot([0, 1], [0, 1], 'k--')\n# Plot the FPR and TPR achieved by our model\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve- Random Forest')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_scores = rf.predict_proba(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def column(matrix, i):\n    return [row[i] for row in matrix]\n\nsub =column(y_scores, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame(sub, columns = ['isFraud'])\ntransactionID = pd.DataFrame(TestTransactionID)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.concat([transactionID, result], axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('sub.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading train_transaction data\ntt = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\nprint(tt.shape)\ntt = reduce_mem_usage(tt)\n\n# loading train_transaction data\nti = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\nprint(ti.shape)\nti = reduce_mem_usage(ti)\n\ntrain = pd.merge(tt, ti, how = 'left')\nprint('Train shape',train.shape)\n\ntrain.head()\n\n\ndel tt, ti\n\n# loading test_transaction data\nts = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\nprint(ts.shape)\nts = reduce_mem_usage(ts)\n\ntsi = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\nprint(tsi.shape)\ntsi = reduce_mem_usage(tsi)\n\ntest = pd.merge(ts, tsi, how = 'left')\nprint('Test shape',test.shape)\ntest.head()\n\ndel ts, tsi","metadata":{"execution":{"iopub.status.busy":"2022-11-25T16:57:02.668074Z","iopub.execute_input":"2022-11-25T16:57:02.669131Z","iopub.status.idle":"2022-11-25T16:59:23.432785Z","shell.execute_reply.started":"2022-11-25T16:57:02.669063Z","shell.execute_reply":"2022-11-25T16:59:23.431266Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(590540, 394)\nMemory usage of dataframe is 1775.15 MB\nMemory usage after optimization is: 487.16 MB\nDecreased by 72.6%\n(144233, 41)\nMemory usage of dataframe is 45.12 MB\nMemory usage after optimization is: 10.00 MB\nDecreased by 77.8%\nTrain shape (590540, 434)\n(506691, 393)\nMemory usage of dataframe is 1519.24 MB\nMemory usage after optimization is: 425.24 MB\nDecreased by 72.0%\n(141907, 41)\nMemory usage of dataframe is 44.39 MB\nMemory usage after optimization is: 9.84 MB\nDecreased by 77.8%\nTest shape (506691, 433)\n","output_type":"stream"}]},{"cell_type":"code","source":"def ColumnsDropper(df):\n    mv = df.isnull().sum()/len(df)\n    df = df.drop(columns=mv[mv>0.8].index)\n    return df\n\ntrain = Devices(train)\ntrain = ColumnsDropper(train)\ntest = DevicesT(test)\ntest = ColumnsDropper(test)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T16:59:23.435615Z","iopub.execute_input":"2022-11-25T16:59:23.436124Z","iopub.status.idle":"2022-11-25T17:00:04.999599Z","shell.execute_reply.started":"2022-11-25T16:59:23.436089Z","shell.execute_reply":"2022-11-25T17:00:04.997401Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"y, TransactionID, TransactionDT = train['isFraud'], train['TransactionID'], train['TransactionDT']\nX = train.drop(['isFraud', 'TransactionID', 'TransactionDT'], axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T17:03:53.140190Z","iopub.execute_input":"2022-11-25T17:03:53.140561Z","iopub.status.idle":"2022-11-25T17:03:55.925634Z","shell.execute_reply.started":"2022-11-25T17:03:53.140531Z","shell.execute_reply":"2022-11-25T17:03:55.924103Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"num_df = X_train.select_dtypes(include=np.number).columns\n# Numerical Preprocessing\nnum_pre = Pipeline(steps =\n                   [(\"Num Imputer\", SimpleImputer(missing_values=np.nan, strategy='median')),\n                    (\"Scaler\", preprocessing.MinMaxScaler()),\n                    (\"PCA\", PCA(n_components = 0.95))])\n\n\ncat_df = X_train.select_dtypes(exclude=np.number).columns\n# Categorical Preprocessing\ncat_pre = Pipeline(steps =\n                   [(\"Cat Imputer\", SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n                    (\"onehot\", OneHotEncoder(handle_unknown='ignore')),\n                    (\"Categorical_Selector\", SelectFromModel(ExtraTreesClassifier(n_estimators=100,\n                                                                       criterion = 'entropy')))])","metadata":{"execution":{"iopub.status.busy":"2022-11-25T17:03:55.927683Z","iopub.execute_input":"2022-11-25T17:03:55.928214Z","iopub.status.idle":"2022-11-25T17:03:56.176635Z","shell.execute_reply.started":"2022-11-25T17:03:55.928171Z","shell.execute_reply":"2022-11-25T17:03:56.175194Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_pre, num_df),\n        ('cat', cat_pre, cat_df)])","metadata":{"execution":{"iopub.status.busy":"2022-11-25T17:03:56.179221Z","iopub.execute_input":"2022-11-25T17:03:56.179676Z","iopub.status.idle":"2022-11-25T17:03:56.188522Z","shell.execute_reply.started":"2022-11-25T17:03:56.179642Z","shell.execute_reply":"2022-11-25T17:03:56.187295Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#from imblearn.pipeline import Pipeline\npipe = Pipeline(steps = \n                [('preprocessor', preprocessor),\n                 #('UnderSampling', RandomUnderSampler(random_state=42)),\n                 ('RandomForest', RandomForestClassifier())])\n\npipe.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T17:03:56.606176Z","iopub.execute_input":"2022-11-25T17:03:56.606615Z","iopub.status.idle":"2022-11-25T17:31:34.294246Z","shell.execute_reply.started":"2022-11-25T17:03:56.606581Z","shell.execute_reply":"2022-11-25T17:31:34.291579Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('Num '\n                                                                   'Imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('Scaler',\n                                                                   MinMaxScaler()),\n                                                                  ('PCA',\n                                                                   PCA(n_components=0.95))]),\n                                                  Index(['TransactionAmt', 'card1', 'card2', 'card3', 'card5', 'addr1', 'addr2',\n       'dist1', 'C1', 'C2',\n       ...\n       'id_01', 'id_02', 'id_05', 'id_06', 'id_11', 'id_13', 'id_17', 'id_1...\n                                                                   SelectFromModel(estimator=ExtraTreesClassifier(criterion='entropy')))]),\n                                                  Index(['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1',\n       'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15',\n       'id_16', 'id_28', 'id_29', 'id_35', 'id_36', 'id_37', 'id_38',\n       'DeviceType', 'device_name', 'browser_id_31', 'version_id_31'],\n      dtype='object'))])),\n                ('RandomForest', RandomForestClassifier())])"},"metadata":{}}]},{"cell_type":"code","source":"y_hat = pipe.predict(X_test)\ny_scores = pipe.predict_proba(X_test)\nprint(metrics.confusion_matrix(y_hat, y_test))\nprint(metrics.accuracy_score(y_test, y_hat))\nprint(metrics.precision_score(y_test, y_hat, average='weighted'))\nprint(metrics.recall_score(y_test, y_hat, average='weighted'))\nprint(metrics.f1_score(y_test, y_hat, average='weighted'))\nprint(metrics.roc_auc_score(y_test, y_scores[:,1]))","metadata":{"execution":{"iopub.status.busy":"2022-11-25T17:31:34.299340Z","iopub.execute_input":"2022-11-25T17:31:34.299754Z","iopub.status.idle":"2022-11-25T17:31:48.042593Z","shell.execute_reply.started":"2022-11-25T17:31:34.299720Z","shell.execute_reply":"2022-11-25T17:31:48.040362Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[[142220   3434]\n [   110   1871]]\n0.9759948521692011\n0.975275473804281\n0.9759948521692011\n0.9706576064691285\n0.9092129519661766\n","output_type":"stream"}]},{"cell_type":"code","source":"y_scores = pipe.predict_proba(test)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T17:32:08.656310Z","iopub.execute_input":"2022-11-25T17:32:08.656753Z","iopub.status.idle":"2022-11-25T17:32:08.711917Z","shell.execute_reply.started":"2022-11-25T17:32:08.656715Z","shell.execute_reply":"2022-11-25T17:32:08.709170Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mEmpty\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_156/4293760742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, **predict_proba_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_proba_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0m_transform_one\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mcolumn_as_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_dataframe_and_transform_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 )\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             )\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 )\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             )\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_pandas_indexing\u001b[0;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# check whether we should index with loc or iloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"int\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['id_01', 'id_02', 'id_05', 'id_06', 'id_11', 'id_13', 'id_17', 'id_19', 'id_20'] not in index\""],"ename":"KeyError","evalue":"\"['id_01', 'id_02', 'id_05', 'id_06', 'id_11', 'id_13', 'id_17', 'id_19', 'id_20'] not in index\"","output_type":"error"}]},{"cell_type":"code","source":"def column(matrix, i):\n    return [row[i] for row in matrix]\n\nsub =column(y_scores, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame(sub, columns = ['isFraud'])\ntransactionID = pd.DataFrame(TestTransactionID)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.concat([transactionID, result], axis =1)\nsub.to_csv('sub.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}